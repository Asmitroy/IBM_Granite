{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asmitroy/IBM_Granite/blob/main/recipes/Summarize/Summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6rko_ANX0EC"
      },
      "source": [
        "# Document Summarization\n",
        "\n",
        "This notebook demonstrates an application of long document summarization techniques to a work of literature using Granite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwS1CzAbaFzq"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Granite utils provides some helpful functions for recipes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2zUHQD71qgqf",
        "outputId": "8c5eea98-745e-42fc-d59a-eaab98626ceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ibm-granite-community/utils\n",
            "  Cloning https://github.com/ibm-granite-community/utils to /tmp/pip-req-build-5vcalqes\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /tmp/pip-req-build-5vcalqes\n",
            "  Resolved https://github.com/ibm-granite-community/utils to commit f5bbcb9dbd203d3a425a64d6af01bf8af989c214\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.11/dist-packages (1.0.6)\n",
            "Requirement already satisfied: docling in /usr/local/lib/python3.11/dist-packages (2.32.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from ibm-granite-community-utils==0.1.dev65) (1.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.4)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.13.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.4)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.4.26)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.11/dist-packages (from docling) (8.1.8)\n",
            "Requirement already satisfied: docling-core<3.0.0,>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.26.0->docling) (2.30.1)\n",
            "Requirement already satisfied: docling-ibm-models<4.0.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from docling) (3.4.3)\n",
            "Requirement already satisfied: docling-parse<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.0.1)\n",
            "Requirement already satisfied: easyocr<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from docling) (1.7.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.2.0)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.1.3)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (11.2.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.5.0)\n",
            "Requirement already satisfied: pylatexenc<3.0,>=2.10 in /usr/local/lib/python3.11/dist-packages (from docling) (2.10)\n",
            "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from docling) (4.30.1)\n",
            "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from docling) (1.1.2)\n",
            "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from docling) (1.0.2)\n",
            "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.4.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.15.3)\n",
            "Requirement already satisfied: typer<0.16.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from docling) (0.15.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (1.1.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (4.23.0)\n",
            "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (3.78.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.9.0)\n",
            "Requirement already satisfied: semchunk<3.0.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.26.0->docling) (2.2.2)\n",
            "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (3.1.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (4.11.0.86)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.6.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (1.11.1.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx<2.0.0,>=1.0.2->docling) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (2.19.1)\n",
            "Requirement already satisfied: mpire[dill] in /usr/local/lib/python3.11/dist-packages (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (2.10.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.0.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.11/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.70.15)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.3.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/ibm-granite-community/utils \\\n",
        "    langchain_community \\\n",
        "    transformers \\\n",
        "    langchain_huggingface \\\n",
        "    replicate \\\n",
        "    docling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydrVWz7EYHh9"
      },
      "source": [
        "## Select your model\n",
        "\n",
        "Select a Granite model from the [`ibm-granite`](https://replicate.com/ibm-granite) org on Replicate. Here we use the Replicate Langchain client to connect to the model.\n",
        "\n",
        "To get set up with Replicate, see [Getting Started with Replicate](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_Replicate.ipynb).\n",
        "\n",
        "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TSkiGBY4qo32"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "\n",
        "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "model = Replicate(\n",
        "    model=model_path,\n",
        "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
        "    model_kwargs={\n",
        "        \"max_tokens\": 2000, # Set the maximum number of tokens to generate as output.\n",
        "        \"min_tokens\": 200, # Set the minimum number of tokens to generate as output.\n",
        "        \"temperature\": 0.75,\n",
        "        \"presence_penalty\": 0,\n",
        "        \"frequency_penalty\": 0,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d0sWaZ7YLHN"
      },
      "source": [
        "## Split a book into chunks\n",
        "\n",
        "The code in the following sections will fetch H.D. Thoreau's \"Walden\" from [Project Gutenberg](https://www.gutenberg.org/) for summarization.\n",
        "\n",
        "We will then chunk the book text so that chunks fit in the context window size of the AI model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYuQmgRJY0n5"
      },
      "source": [
        "### Count the tokens\n",
        "\n",
        "Before sending our book chunks to the AI model, it's crucial to understand how much of the model's capacity we're using. Language models typically have a limit on the number of tokens they can process in a single request.\n",
        "\n",
        "Key points:\n",
        "- We're using the [`granite-3.3-8b-instruct`](https://huggingface.co/ibm-granite/granite-3.3-8b-instruct) model, which has a context window of 128K tokens.\n",
        "- Tokenization can vary between models, so we use the specific tokenizer for our chosen model.\n",
        "\n",
        "Understanding token count helps us optimize our prompts and ensure we're using the model efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JqmvTqbWPgl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rippHzv7uMZ"
      },
      "source": [
        "### Summary of Summaries\n",
        "\n",
        "Here we use a hierarchical abstractive summarization technique to adapt to the context length of the model. Our approach uses [Docling](https://docling-project.github.io/docling/) to understand the document's structure, chunk the document into text passages, and group the text passages by chapter which we can then summarize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V_DbIFLF7uMZ",
        "outputId": "cd5e7320-7b26-4fd7-a02b-d37477b883ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 documents created\n",
            "Max document size: 38299 tokens\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "from typing import Iterator, Callable\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling_core.transforms.chunker.hierarchical_chunker import HierarchicalChunker\n",
        "from docling_core.transforms.chunker.base import BaseChunk\n",
        "\n",
        "def chunk_document(source: str, *, dropwhile: Callable[[BaseChunk], bool] = lambda c: False, takewhile: Callable[[BaseChunk], bool] = lambda c: True) -> Iterator[BaseChunk]:\n",
        "    \"\"\"Read the document and perform a hierarchical chunking\"\"\"\n",
        "    converter = DocumentConverter()\n",
        "    chunks = HierarchicalChunker().chunk(converter.convert(source=source).document)\n",
        "    return itertools.takewhile(takewhile, itertools.dropwhile(dropwhile, chunks))\n",
        "\n",
        "def merge_chunks(chunks: Iterator[BaseChunk], *, headings: Callable[[BaseChunk], list[str]] = lambda c: c.meta.headings) -> Iterator[dict[str, str]]:\n",
        "    \"\"\"Merge chunks having the same headings\"\"\"\n",
        "    prior_headings: list[str] | None = None\n",
        "    document: dict[str, str] = {}\n",
        "    doc_id = 0\n",
        "    for chunk in chunks:\n",
        "        text = chunk.text.replace('\\r\\n', '\\n')\n",
        "        current_headings = headings(chunk)\n",
        "        if prior_headings != current_headings:\n",
        "            if document:\n",
        "                yield document\n",
        "            prior_headings = current_headings\n",
        "            document = {\n",
        "                'doc_id': str(doc_id:=doc_id+1),\n",
        "                'title': \" - \".join(current_headings),\n",
        "                'text': text\n",
        "            }\n",
        "        else:\n",
        "            document['text'] += f\"\\n\\n{text}\"\n",
        "    if document:\n",
        "        yield document\n",
        "\n",
        "def chunk_dropwhile(chunk: BaseChunk) -> bool:\n",
        "    \"\"\"Ignore front matter prior to the book start\"\"\"\n",
        "    return \"WALDEN\" not in chunk.meta.headings\n",
        "\n",
        "def chunk_takewhile(chunk: BaseChunk) -> bool:\n",
        "    \"\"\"Ignore remaining chunks once we see this heading\"\"\"\n",
        "    return \"ON THE DUTY OF CIVIL DISOBEDIENCE\" not in chunk.meta.headings\n",
        "\n",
        "def chunk_headings(chunk: BaseChunk) -> list[str]:\n",
        "    \"\"\"Use the h1 and h2 (chapter) headings\"\"\"\n",
        "    return chunk.meta.headings[:2]\n",
        "\n",
        "documents: list[dict[str, str]] = list(merge_chunks(\n",
        "    chunk_document(\n",
        "        \"https://www.gutenberg.org/cache/epub/205/pg205-images.html\",\n",
        "        dropwhile=chunk_dropwhile,\n",
        "        takewhile=chunk_takewhile,\n",
        "    ),\n",
        "    headings=chunk_headings,\n",
        "))\n",
        "\n",
        "print(f\"{len(documents)} documents created\")\n",
        "print(f\"Max document size: {max(len(tokenizer.tokenize(document['text'])) for document in documents)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJTAK8J-7uMZ"
      },
      "source": [
        "## Summarize the chunks\n",
        "\n",
        "Here we define a method to generate a response using a list of documents and a user prompt about those documents.\n",
        "\n",
        "We create the prompt according to the [Granite Prompting Guide](https://www.ibm.com/granite/docs/models/granite/#chat-template) and provide the documents using the `documents` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IMVseh3Z7uMa"
      },
      "outputs": [],
      "source": [
        "def generate(user_prompt: str, documents: list[dict[str, str]]):\n",
        "    \"\"\"Use the chat template to format the prompt\"\"\"\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        conversation=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt,\n",
        "        }],\n",
        "        documents=documents, # This uses the documents support in the Granite chat template\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False,\n",
        "    )\n",
        "\n",
        "    print(f\"Input size: {len(tokenizer.tokenize(prompt))} tokens\")\n",
        "    output = model.invoke(prompt)\n",
        "    print(f\"Output size: {len(tokenizer.tokenize(output))} tokens\")\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh82HB177uMa"
      },
      "source": [
        "For each chapter, we create a separate summary. This can take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R0Yk_Jy-7uMa",
        "outputId": "824a30ad-68ba-4512-e18e-339d3e6834ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================= WALDEN - Economy (1/18) =============================\n",
            "Input size: 38447 tokens\n",
            "Output size: 236 tokens\n",
            "============================= WALDEN - Where I Lived, and What I Lived For (2/18) =============================\n",
            "Input size: 9138 tokens\n",
            "Output size: 220 tokens\n",
            "============================= WALDEN - Reading (3/18) =============================\n",
            "Input size: 5724 tokens\n",
            "Output size: 221 tokens\n",
            "============================= WALDEN - Sounds (4/18) =============================\n",
            "Input size: 9107 tokens\n",
            "Output size: 227 tokens\n",
            "============================= WALDEN - Solitude (5/18) =============================\n",
            "Input size: 5219 tokens\n",
            "Output size: 204 tokens\n",
            "============================= WALDEN - Visitors (6/18) =============================\n",
            "Input size: 7153 tokens\n",
            "Output size: 228 tokens\n",
            "============================= WALDEN - The Bean-Field (7/18) =============================\n",
            "Input size: 6345 tokens\n",
            "Output size: 262 tokens\n",
            "============================= WALDEN - The Village (8/18) =============================\n",
            "Input size: 3138 tokens\n",
            "Output size: 203 tokens\n",
            "============================= WALDEN - The Ponds (9/18) =============================\n",
            "Input size: 13846 tokens\n",
            "Output size: 285 tokens\n",
            "============================= WALDEN - Baker Farm (10/18) =============================\n",
            "Input size: 4162 tokens\n",
            "Output size: 223 tokens\n",
            "============================= WALDEN - Higher Laws (11/18) =============================\n",
            "Input size: 6469 tokens\n",
            "Output size: 205 tokens\n",
            "============================= WALDEN - Brute Neighbors (12/18) =============================\n",
            "Input size: 7284 tokens\n",
            "Output size: 237 tokens\n",
            "============================= WALDEN - House-Warming (13/18) =============================\n",
            "Input size: 8671 tokens\n",
            "Output size: 281 tokens\n",
            "============================= WALDEN - Former Inhabitants and Winter Visitors (14/18) =============================\n",
            "Input size: 7552 tokens\n",
            "Output size: 310 tokens\n",
            "============================= WALDEN - Winter Animals (15/18) =============================\n",
            "Input size: 5757 tokens\n",
            "Output size: 210 tokens\n",
            "============================= WALDEN - The Pond in Winter (16/18) =============================\n",
            "Input size: 7789 tokens\n",
            "Output size: 322 tokens\n",
            "============================= WALDEN - Spring (17/18) =============================\n",
            "Input size: 10413 tokens\n",
            "Output size: 287 tokens\n",
            "============================= WALDEN - Conclusion (18/18) =============================\n",
            "Input size: 7053 tokens\n",
            "Output size: 231 tokens\n",
            "Summary count: 18\n"
          ]
        }
      ],
      "source": [
        "if get_env_var('GRANITE_TESTING', 'false').lower() == 'true':\n",
        "    documents = documents[:5] # shorten testing work\n",
        "\n",
        "user_prompt = \"\"\"\\\n",
        "Using only the the book chapter document, compose a summary of the book chapter.\n",
        "Your response should only include the summary. Do not provide any further explanation.\"\"\"\n",
        "\n",
        "summaries: list[dict[str, str]] = []\n",
        "\n",
        "for i, document in enumerate(documents):\n",
        "    print(f\"============================= {document['title']} ({i+1}/{len(documents)}) =============================\")\n",
        "    output = generate(user_prompt, [document])\n",
        "    summaries.append({\n",
        "        'doc_id': document['doc_id'],\n",
        "        'title': document['title'],\n",
        "        'text': output,\n",
        "    })\n",
        "\n",
        "print(\"Summary count: \" + str(len(summaries)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfbeaBcz7uMa"
      },
      "source": [
        "## Create the Final Summary\n",
        "\n",
        "Now we need to summarize the chapter summaries. We prompt the model to create a unified summary of the chapter summaries we previously generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R1JTTwyE7uMa",
        "outputId": "50041f64-44f2-4ea6-ddd2-dbe692adb530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: 4790 tokens\n",
            "Output size: 230 tokens\n",
            "The book, \"Walden\" by Henry David Thoreau, is a reflection on simple living and\n",
            "self-reliance. Thoreau describes his two-year experiment of living in a cabin\n",
            "near Walden Pond, emphasizing the importance of simplicity, self-sufficiency,\n",
            "and connection with nature. He criticizes the common mode of living, which\n",
            "prioritizes accumulating wealth and material possessions over living a life of\n",
            "integrity. Thoreau values experiences and freedom over material wealth,\n",
            "appreciating the beauty of the natural world and the importance of living in the\n",
            "present moment. He explores various themes, such as the futility of owning land,\n",
            "the significance of owning one's time, the transient nature of human activity\n",
            "compared to nature's endurance, and the interconnectedness of all things. The\n",
            "book encourages readers to live authentically, find contentment in their lives,\n",
            "and seek genuine experiences, ultimately advocating for an examined life guided\n",
            "by inner convictions and a deep appreciation for the world's wonders.\n"
          ]
        }
      ],
      "source": [
        "from ibm_granite_community.notebook_utils import wrap_text\n",
        "\n",
        "user_prompt = \"\"\"\\\n",
        "Using only the book chapter summary documents, compose a single, unified summary of the book.\n",
        "Your response should only include the unified summary. Do not provide any further explanation.\"\"\"\n",
        "\n",
        "output = generate(user_prompt, summaries)\n",
        "print(wrap_text(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv-5G-Zu7uMa"
      },
      "source": [
        "So we have now summarized a document larger than the AI model's context window length by breaking the document down into smaller pieces to summarize and then summarizing those summaries."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}